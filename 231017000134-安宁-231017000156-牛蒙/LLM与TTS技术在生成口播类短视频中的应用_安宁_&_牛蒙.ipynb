{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ze2bTaYxsA3X"
      },
      "source": [
        "# LLM与TTS技术在生成口播类短视频中的应用 - 安宁 & 牛蒙"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3fHy49csPom"
      },
      "source": [
        "## 背景介绍\n",
        "在**自媒体**时代，大部分人都有分享自己经历或者经验的需求。最初通过公众号或者微博平台，自媒体人员只需要有写作能力就可以获得巨大的流量。而随着短视频的流行，具备将文章变为视频，上传到各类视频平台的能力，会成为自媒体人员的一个优势。但**并不是每个人都具备良好的口播能力**或者视频制作的能力，所以这里提出了一个口播类短视频自动生成应用。\n",
        "\n",
        "\n",
        "此应用的功能：\n",
        "1. 使用**大语言模型（large language model，LLM）**对口播文稿进行优化\n",
        "2. 使用**test-to-speech(TTS)模型**自动生成高质量的**口播音频**。\n",
        "3. 自动生成**字幕**文件。\n",
        "4. 自动将**音频文件、字幕文件、图片素材**合并为视频文件。\n",
        "\n",
        "![image.png](https://obsidian-1256183154.cos.ap-beijing.myqcloud.com/obsidian202312031302588.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilvobVvkBPxe"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pXB6FWPuwfrN"
      },
      "source": [
        "## 核心技术\n",
        "\n",
        "此应用的实现使用到了两项计算机相关的核心技术：**test-to-speech**和**Audio and video processing**.\n",
        "\n",
        "\n",
        "### 1. text-to-speech（TTS）\n",
        "\n",
        "是将计算机自己产生的、或外部输入的**文字信息**转变为可以听得懂的、流利的**口语**输出的技术。\n",
        "\n",
        "![image.png](https://obsidian-1256183154.cos.ap-beijing.myqcloud.com/obsidian202312031148567.png)\n",
        "\n",
        "\n",
        "TTS 详细流程**[0]**：\n",
        "\n",
        "![image.png](https://obsidian-1256183154.cos.ap-beijing.myqcloud.com/obsidian202312031148604.png)\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "### 2. Audio and video processing\n",
        "\n",
        "音视频处理本身是需要相当丰富的专业技术来完成。幸运的是FFmpeg框架简化了此过程，并提供一种声明性方式来表达我们处理视频所需的意图[1]。\n",
        "\n",
        "FFmpeg是处理多媒体内容(如音频、视频、字幕和相关元数据)的库和工具的集合[2]。\n",
        "\n",
        "![image.png](https://obsidian-1256183154.cos.ap-beijing.myqcloud.com/obsidian202312031158800.png)\n",
        "\n",
        "参考：\n",
        "\n",
        "[0] Deep Voice: Real-time Neural Text-to-Speech. 2017. Arik, Sercan O., et al.\n",
        "\n",
        "[1] How to process video with FFmpeg. Framework syntax from Zero to Hero\n",
        "\n",
        "[2] https://github.com/FFmpeg/FFmpeg\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRU4pMSYQU8D"
      },
      "source": [
        "## 具体实现\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GkPVYI_Bfk-J",
        "outputId": "f1b78daf-65be-42b0-d32d-e855e8412d27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "python3 is already the newest version (3.10.6-1~22.04).\n",
            "python3 set to manually installed.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 15 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 15 not upgraded.\n",
            "Collecting openai\n",
            "  Downloading openai-1.3.7-py3-none-any.whl (221 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.4/221.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting edge-tts\n",
            "  Downloading edge_tts-6.1.9-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: anyio<4,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.25.2-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai) (4.5.0)\n",
            "Requirement already satisfied: aiohttp>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from edge-tts) (3.9.1)\n",
            "Collecting certifi==2023.07.22 (from edge-tts)\n",
            "  Downloading certifi-2023.7.22-py3-none-any.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.3/158.3 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.0->edge-tts) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.0->edge-tts) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.0->edge-tts) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.0->edge-tts) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.0->edge-tts) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.0->edge-tts) (4.0.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.2.0)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h11, certifi, httpcore, httpx, edge-tts, openai\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2023.11.17\n",
            "    Uninstalling certifi-2023.11.17:\n",
            "      Successfully uninstalled certifi-2023.11.17\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed certifi-2023.7.22 edge-tts-6.1.9 h11-0.14.0 httpcore-1.0.2 httpx-0.25.2 openai-1.3.7\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "certifi"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!apt -y install python3\n",
        "!apt -y install ffmpeg\n",
        "!pip install openai edge-tts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UgPChV3fEau"
      },
      "source": [
        "### 1. 读取文稿文本文件，通过大语言模型对文稿进行优化\n",
        "\n",
        "这里使用了ChatGPT的API接口，通过角色扮演的方式使ChatGPU扮演一名写作专家。然后让其对口播文稿进行优化。\n",
        "\n",
        "可以调用大语言模型进行替换。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_yXAioeS7Fw"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "\n",
        "openai.api_key = \"API_KEY\"\n",
        "\n",
        "model_engine = \"gpt-3.5-turbo\"\n",
        "\n",
        "input_text = \"今天给大家分享一篇ICCV 2023的文章,AC-Former,首先我们把注意力转移至画面坐标的图片区域，红色和蓝色框即为这篇文章的创新部分\"\n",
        "\n",
        "messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful writing assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Please optimize the following document to make it more suitable for oral presentation. {input_text}\"},\n",
        "]\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "  model=model_engine,\n",
        "  messages=[{\"role\": \"user\", \"content\": input_text }]\n",
        ")\n",
        "\n",
        "# response将会得到一个类似这样结构的json消息\n",
        "# {\n",
        "#  'id': 'chatcmpl-',\n",
        "#  'object': 'chat.completion',\n",
        "#  'created': ,\n",
        "#  'model': 'gpt-3.5-turbo',\n",
        "#  'usage': {'prompt_tokens': , 'completion_tokens': , 'total_tokens': },\n",
        "#  'choices': [\n",
        "#    {\n",
        "#     'message': {\n",
        "#       'role': 'assistant',\n",
        "#       'content': ''},\n",
        "#     'finish_reason': 'stop',\n",
        "#     'index': 0\n",
        "#    }\n",
        "#   ]\n",
        "# }\n",
        "\n",
        "# 解析响应并输出结果\n",
        "output_text = response['choices'][0]['message']['content']\n",
        "print(\"优化后的文稿: {output_text}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Guh8quPjUshf"
      },
      "source": [
        "### 2. 读取优化后的文稿文件，通过TTS模型生成音频文件和字幕文件\n",
        "\n",
        "选择了Microsoft Edge TTS接口，其基于Microsoft Azure服务实现，提供了的语音合成算法,生成的音频文件具有更自然的语音口播效果。此接口通过Python库edge_tts**[3]**实现。\n",
        "\n",
        "可以通过FaceBook的SeamlessM4T**[4]**，microsoft的SpeechT5**[5]**和NaturalSpeech**[6]**模型进行替换。\n",
        "\n",
        "\n",
        "参考：\n",
        "\n",
        "[3] https://github.com/rany2/edge-tts\n",
        "\n",
        "[4] https://github.com/facebookresearch/seamless_communication\n",
        "\n",
        "[5] https://github.com/microsoft/SpeechT5\n",
        "\n",
        "[6] https://speechresearch.github.io/naturalspeech/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S8eVuNf4ypPq"
      },
      "outputs": [],
      "source": [
        "input_text = \"今天给大家分享一篇ICCV 2023的文章,AC-Former,首先我们把注意力转移至画面坐标的图片区域，红色和蓝色框即为这篇文章的创新部分\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vLbHc9vgVMZi"
      },
      "outputs": [],
      "source": [
        "import asyncio\n",
        "\n",
        "import edge_tts\n",
        "\n",
        "TEXT = input_text\n",
        "VOICE = \"zh-CN-XiaoyiNeural\"\n",
        "\n",
        "OUTPUT_FILE = \"test.mp3\"\n",
        "WEBVTT_FILE = \"test.vtt\"\n",
        "\n",
        "\n",
        "async def _main() -> None:\n",
        "    communicate = edge_tts.Communicate(TEXT, VOICE)\n",
        "    submaker = edge_tts.SubMaker()\n",
        "    with open(OUTPUT_FILE, \"wb\") as file:\n",
        "        async for chunk in communicate.stream():\n",
        "            if chunk[\"type\"] == \"audio\":\n",
        "                file.write(chunk[\"data\"])\n",
        "            elif chunk[\"type\"] == \"WordBoundary\":\n",
        "                submaker.create_sub((chunk[\"offset\"], chunk[\"duration\"]), chunk[\"text\"])\n",
        "\n",
        "    with open(WEBVTT_FILE, \"w\", encoding=\"utf-8\") as file:\n",
        "        file.write(submaker.generate_subs())\n",
        "\n",
        "await _main()\n",
        "# if __name__ == \"__main__\":\n",
        "    # asyncio.run(_main())\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "869j7x4oVPke"
      },
      "source": [
        "### 3. 读取图片素材生成无语音的短视频文件"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8udarhYVZ_Y",
        "outputId": "ed250fbf-da12-4e15-e68d-23c5f300e857"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "256"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "cmd = \"ffmpeg -r 1 -i %d.jpeg test.mp4\"\n",
        "\n",
        "os.system(cmd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQNW8aD2zZ1m",
        "outputId": "af196424-a99e-4b50-8009-755114f0b8e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "y\n",
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "Input #0, image2, from '%d.jpeg':\n",
            "  Duration: 00:00:00.04, start: 0.000000, bitrate: N/A\n",
            "  Stream #0:0: Video: mjpeg (Baseline), yuvj420p(pc, bt470bg/unknown/unknown), 1224x646 [SAR 96:96 DAR 36:19], 25 fps, 25 tbr, 25 tbn, 25 tbc\n",
            "File 'test.mp4' already exists. Overwrite? [y/N] Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (mjpeg (native) -> h264 (libx264))\n",
            "Press [q] to stop, [?] for help\n",
            "\u001b[1;36m[libx264 @ 0x56867521db00] \u001b[0musing SAR=1/1\n",
            "\u001b[1;36m[libx264 @ 0x56867521db00] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
            "\u001b[1;36m[libx264 @ 0x56867521db00] \u001b[0mprofile High, level 3.1, 4:2:0, 8-bit\n",
            "\u001b[1;36m[libx264 @ 0x56867521db00] \u001b[0m264 - core 163 r3060 5db6aa6 - H.264/MPEG-4 AVC codec - Copyleft 2003-2021 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=3 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=1 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
            "Output #0, mp4, to 'test.mp4':\n",
            "  Metadata:\n",
            "    encoder         : Lavf58.76.100\n",
            "  Stream #0:0: Video: h264 (avc1 / 0x31637661), yuvj420p(pc, bt470bg/unknown/unknown, progressive), 1224x646 [SAR 96:96 DAR 36:19], q=2-31, 1 fps, 16384 tbn\n",
            "    Metadata:\n",
            "      encoder         : Lavc58.134.100 libx264\n",
            "    Side data:\n",
            "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
            "frame=    1 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    \rframe=    1 fps=0.0 q=17.0 Lsize=     124kB time=00:00:00.00 bitrate=16594623.0kbits/s speed=0.000737x    \n",
            "video:123kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.673095%\n",
            "\u001b[1;36m[libx264 @ 0x56867521db00] \u001b[0mframe I:1     Avg QP:15.71  size:125000\n",
            "\u001b[1;36m[libx264 @ 0x56867521db00] \u001b[0mmb I  I16..4: 34.0% 23.4% 42.6%\n",
            "\u001b[1;36m[libx264 @ 0x56867521db00] \u001b[0m8x8 transform intra:23.4%\n",
            "\u001b[1;36m[libx264 @ 0x56867521db00] \u001b[0mcoded y,uvDC,uvAC intra: 34.6% 40.5% 35.4%\n",
            "\u001b[1;36m[libx264 @ 0x56867521db00] \u001b[0mi16 v,h,dc,p: 71% 21%  8%  0%\n",
            "\u001b[1;36m[libx264 @ 0x56867521db00] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 55% 10% 29%  1%  1%  1%  0%  1%  3%\n",
            "\u001b[1;36m[libx264 @ 0x56867521db00] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 40% 27%  9%  2%  4%  5%  4%  3%  5%\n",
            "\u001b[1;36m[libx264 @ 0x56867521db00] \u001b[0mi8c dc,h,v,p: 59% 19% 20%  1%\n",
            "\u001b[1;36m[libx264 @ 0x56867521db00] \u001b[0mkb/s:1000.00\n"
          ]
        }
      ],
      "source": [
        "!ffmpeg -r 1 -i %d.jpeg test.mp4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3o6fGyDkU2UH"
      },
      "source": [
        "### 4. 将将音频文件、字幕文件、视频文件合成为一个完整的短视频文件"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YS-j3SZbVXE_",
        "outputId": "95abaa0b-3965-49c7-c274-27f751655d7b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "256"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#\n",
        "\n",
        "import os\n",
        "\n",
        "cmd = \"ffmpeg -i test.mp4 -i test.vtt -i test.mp3 -map 0:v -map 1:s -map 2:a -c:v copy -c:a copy -c:s mov_text output.mp4\"\n",
        "\n",
        "os.system(cmd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qE9AAUQJA1AP",
        "outputId": "0c29b449-d227-47cd-b03e-ec667cf16185"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'test.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : isom\n",
            "    minor_version   : 512\n",
            "    compatible_brands: isomiso2avc1mp41\n",
            "    encoder         : Lavf58.76.100\n",
            "  Duration: 00:00:01.00, start: 0.000000, bitrate: 1012 kb/s\n",
            "  Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuvj420p(pc, bt470bg/unknown/unknown), 1224x646 [SAR 1:1 DAR 36:19], 1005 kb/s, 1 fps, 1 tbr, 16384 tbn, 2 tbc (default)\n",
            "    Metadata:\n",
            "      handler_name    : VideoHandler\n",
            "      vendor_id       : [0][0][0][0]\n",
            "Input #1, webvtt, from 'test.vtt':\n",
            "  Duration: N/A, bitrate: N/A\n",
            "  Stream #1:0: Subtitle: webvtt\n",
            "\u001b[0;35m[mp3 @ 0x55d6c3f24e80] \u001b[0m\u001b[0;33mEstimating duration from bitrate, this may be inaccurate\n",
            "\u001b[0mInput #2, mp3, from 'test.mp3':\n",
            "  Duration: 00:00:12.91, start: 0.000000, bitrate: 48 kb/s\n",
            "  Stream #2:0: Audio: mp3, 24000 Hz, mono, fltp, 48 kb/s\n",
            "Output #0, mp4, to 'output.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : isom\n",
            "    minor_version   : 512\n",
            "    compatible_brands: isomiso2avc1mp41\n",
            "    encoder         : Lavf58.76.100\n",
            "  Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuvj420p(pc, bt470bg/unknown/unknown), 1224x646 [SAR 1:1 DAR 36:19], q=2-31, 1005 kb/s, 1 fps, 1 tbr, 16384 tbn, 16384 tbc (default)\n",
            "    Metadata:\n",
            "      handler_name    : VideoHandler\n",
            "      vendor_id       : [0][0][0][0]\n",
            "  Stream #0:1: Subtitle: mov_text (tx3g / 0x67337874)\n",
            "    Metadata:\n",
            "      encoder         : Lavc58.134.100 mov_text\n",
            "  Stream #0:2: Audio: mp3 (mp4a / 0x6134706D), 24000 Hz, mono, fltp, 48 kb/s\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (copy)\n",
            "  Stream #1:0 -> #0:1 (webvtt (native) -> mov_text (native))\n",
            "  Stream #2:0 -> #0:2 (copy)\n",
            "Press [q] to stop, [?] for help\n",
            "frame=    1 fps=0.0 q=-1.0 size=       0kB time=00:00:00.00 bitrate=6295.1kbits/s speed=0.298x    \rframe=    1 fps=0.0 q=-1.0 Lsize=     201kB time=00:00:12.88 bitrate= 127.5kbits/s speed=1.64e+03x    \n",
            "video:123kB audio:76kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.998215%\n"
          ]
        }
      ],
      "source": [
        "!ffmpeg -i test.mp4 -i test.vtt -i test.mp3 -map 0:v -map 1:s -map 2:a -c:v copy -c:a copy -c:s mov_text output.mp4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDiYfOvdYHqG"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdhVzEw3hmYl"
      },
      "source": [
        "项目风险：营销号滥用"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
